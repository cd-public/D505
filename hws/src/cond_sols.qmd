---
title: "Conditional Probability"
author: "Prof. Calvin"
date: "02/17/2025"

format: 
  html:  # You will quite likely want to change all but the last one, to taste
    theme: superhero  
    mainfont: monospace
    highlight-style: github
    title-block-banner: true
    embed-resources: true
---

**Abstract:**

- This is a technical blog post of **both** an HTML file *and* [.qmd file](https://raw.githubusercontent.com/cd-public/D505/refs/heads/master/hws/src/cond_sols.qmd) hosted on GitHub pages.

# 0. Quarto Type-setting

- This document is rendered with Quarto, and configured to embed an images using the `embed-resources` option in the header.
- If you wish to use a similar header, here's is the format specification for this document:

```email
format: 
  html:
    embed-resources: true
```

# 1. Setup

```{r setup}
sh <- suppressPackageStartupMessages
sh(library(tidyverse))
sh(library(caret))
sh(library(naivebayes)) # bae caught me naivin'
sh(library(tidytext))
wine <- readRDS(gzcon(url("https://github.com/cd-public/D505/raw/master/dat/pinot.rds")))
```

# 2. Conditional Probability

- Calculate the probability that a Pinot comes from Burgundy given it has the word 'fruit' in the description.
  - Take $A$ to be the probability that a Pinot was grown in Burgundy.
  - Take $B$ to be the probability that Pinot has the word 'fruit' in it's description.

$$
P(A|B)
$$

```{r pab}
nrow(filter(wine,province=="Burgundy" & str_detect(description,"fruit")))/nrow(filter(wine, str_detect(description,"fruit")))
```

# 3. Naive Bayes Algorithm

- We train a naive bayes algorithm to classify a wine's province using:

1. An 80-20 train-test split.
2. Three features engineered from the description
3. 5-fold cross validation.

- We report Kappa after using the model to predict provinces in the holdout sample.

```{r nb train}
wino = wine %>% 
  mutate(cherry = str_detect(description,"cherry")) %>% 
  mutate(chocolate = str_detect(description,"chocolate")) %>%
  mutate(earth = str_detect(description,"earth")) %>%
  select(-description)

wine_index <- createDataPartition(wino$province, p = 0.80, list = FALSE)
train <- wino[ wine_index, ]
test <- wino[-wine_index, ]

fit <- train(province ~ .,
             data = train, 
             method = "naive_bayes",
             metric = "Kappa",
             trControl = trainControl(method = "cv", number = 5))

confusionMatrix(predict(fit, test),factor(test$province))
```


# 4. Frequency Differences

- We find the three words that most distinguish New York Pinots from all other Pinots.

> Calculate relative word count.

```{r wordcount}
wc <- function(df, omits) {
  count <- nrow(df)
  df %>%
    unnest_tokens(word, description) %>% anti_join(stop_words) %>%
    filter(!(word %in% omits)) %>% 
    group_by(word) %>% mutate(total=n()) %>% count() %>%
    ungroup() %>% mutate(n=n/count)
}
```

> Make corresponding dataframes.
    
```{r dfs}
omits = c("pinot", "noir", "wine")
wc_ny <- wc(wine %>% filter(province=="New_York") %>% select(description), omits)
wc_no <- wc(wine %>% filter(province!="New_York") %>% select(description), omits)
```
> Calculate difference in relative frequencies.

```{r freq}
diff <- wc_ny %>%
    inner_join(wc_no, by = "word", suffix = c("_ny", "_no")) %>%
    mutate(diff = n_ny - n_no) %>%
    arrange(desc(abs(diff)))
    
diff %>% head(3)
```

> Plot it.

```{r}
sh(library(plotly))

plot_ly(diff %>% top_n(25, diff), 
        x = ~n_ny, y = ~n_no, z = ~diff, text = ~word, 
        type = 'scatter3d', mode = 'markers+text', 
        marker = list(size = 5, color = ~diff, showscale = TRUE) %>%
    layout(title = "3D Scatterplot of Word Frequencies",
           scene = list(
               xaxis = list(title = "Frequency in New York Pinots"),
               yaxis = list(title = "Frequency in Other Pinots"),
               zaxis = list(title = "Difference in Frequency")
           ))
```