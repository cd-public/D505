---
title: "Deep Learning"
author: "Jameson Watts, Ph.D."
date: "04/19/2020"
output: 
  pdf_document:
    df_print: kable
    fig_width: 11
    fig_height: 8
---

## Agenda

1. Q&A with CravenSpeed
2. Anatomy of a Technical Presentation
3. Quick Review of Bagging and Boosting
4. Deep Learning Concepts
5. Dinner
6. Neural net implementation
7. Groupwork

# Review of Bagging and Boosting

The goal is to decrease the variance (bagging) or bias (boosting) in our models.

- Step 1: producing a distribution of simple ML models on subsets of the original data.
- Step 2: combine the distribution into one “aggregated” model.

![](images/biasvariance2.png)
# Dinner and (virtual) high fives


# Neural Net implementations

## Setup
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidymodels)
library(tidyverse)
bank <- read_rds("../resources/BankChurners.rds") %>% 
  mutate(Churn = as_factor(Churn)) %>%
  mutate(Churn = fct_relevel(Churn, "yes","no"))

set.seed(504)
data_split <- initial_split(bank, prop = 3/4)

bank_train <- training(data_split)
bank_test  <- testing(data_split)
```

# Set a baseline with extreme gradient boosting

```{r}
bank_rec <- 
  recipe(Churn ~ ., data = bank_train) %>% 
  step_BoxCox(all_numeric()) %>% 
  step_normalize(all_numeric()) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%  # dummy variables for all factor/character columns except for the outcome (i.e. Churn)
  step_zv(all_predictors()) %>%  # remove all zero variance predictors (i.e. low frequency dummies)
  step_upsample(Churn) 
  
xgb_spec <- 
   boost_tree() %>% 
   set_engine("xgboost") %>% 
   set_mode("classification")

bank_wflow <- 
  workflow() %>% 
  add_model(xgb_spec) %>% 
  add_recipe(bank_rec)

bank_fit <- ## fit the model
  bank_wflow %>% 
  fit(data = bank_train)

cm <- predict(bank_fit, bank_test) %>%
  bind_cols(bank_test %>% select(Churn))  %>% 
  conf_mat(truth = Churn, .pred_class)

cm %>% autoplot()
cm %>% summary()
```


# Compare with Neural Net

```{r}
  
nnet_spec <- 
   mlp(hidden_units = 11) %>% 
   set_engine("nnet") %>% 
   set_mode("classification")

bank_wflow <- 
  workflow() %>% 
  add_model(nnet_spec) %>% 
  add_recipe(bank_rec)

bank_fit <- ## fit the model
  bank_wflow %>% 
  fit(data = bank_train)

cm <- predict(bank_fit, bank_test) %>%
  bind_cols(bank_test %>% select(Churn))  %>% 
  conf_mat(truth = Churn, .pred_class)

cm %>% autoplot()
cm %>% summary()
```


## Let's do some tuning

```{r}
mlp_spec <- 
  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
  set_engine("nnet", trace = 0) %>% 
  set_mode("classification")


mlp_param <- parameters(mlp_spec)
mlp_param %>% pull_dials_object("hidden_units")
mlp_param %>% pull_dials_object("penalty")
mlp_param %>% pull_dials_object("epochs")
```
## defining your own grid

```{r}
crossing(
  hidden_units = 1:3,
  penalty = c(0.0, 0.1),
  epochs = c(100, 200)
)
```

## using grid_regular

```{r}
grid_regular(mlp_param, levels = 2)
```

## setting different levels

```{r}
grid_regular(mlp_param, levels = c(hidden_units = 3, penalty = 2, epochs = 2))
```
## let's change the defaults

```{r}
mlp_wflow <- 
  workflow() %>% 
  add_model(mlp_spec) %>% 
  add_recipe(bank_rec)

mlp_param <- 
  mlp_wflow %>% 
  parameters() %>% 
  update(
    epochs = epochs(c(100, 500)),
    hidden_units = hidden_units(c(5, 50))
  )
```

## run all models across the grid

```{r}
set.seed(504)
folds <- vfold_cv(bank_train, v = 2)

mlp_reg_tune <-
  mlp_wflow %>%
  tune_grid(
    folds,
    grid = mlp_param %>% grid_regular(levels = 3)
  )

autoplot(mlp_reg_tune)
```

```{r}
show_best(mlp_reg_tune) %>% select(-.estimator)
```


## Finalize, fit and pull our optimized model

```{r}
best_net <- mlp_reg_tune %>%
  select_best("roc_auc")

final_wflow <- 
  mlp_wflow %>% 
  finalize_workflow(best_net)

bank_fit <- 
  final_wflow %>%
  fit(data = bank_train)
  
library(vip)

bank_fit %>%
  pull_workflow_fit() %>% 
  vip()
```

## Let's see how it does out of sample

```{r}

cm <- predict(bank_fit, bank_test) %>%
  bind_cols(bank_test %>% select(Churn))  %>% 
  conf_mat(truth = Churn, .pred_class)

cm %>% autoplot()
cm %>% summary()

```


# Other resources

https://srdas.github.io/DLBook/

